{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import deque\n",
    "from env import SimpleAmpEnv\n",
    "from DQNagent import DQNagent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change clab to True if using google colaboratory\n",
    "clab = False\n",
    "\n",
    "if clab:\n",
    "    from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_Layer size: 3\n",
      "Output_Layer size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lab2020/opt/anaconda3/envs/learning/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "# Initialize environment\n",
    "env = SimpleAmpEnv(ideal=False, reward_type=\"AutoCkt\")\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# Check the Input layer size, and Output layer size\n",
    "print(f\"Input_Layer size: {state_size}\")\n",
    "print(f\"Output_Layer size: {action_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 68\n",
      "Trainable params: 68\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 68\n",
      "Trainable params: 68\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 12:27:12.102184: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-16 12:27:12.102778: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "agent = DQNagent(state_size, action_size)\n",
    "agent.main_model.summary()\n",
    "agent.target_model.summary()\n",
    "if clab:\n",
    "    plot_model(agent.main_model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.0560 action: 0, epsilon: 1.0000\n",
      "step: 19, Current: 0.0540 action: 2, epsilon: 1.0000\n",
      "step: 29, Current: 0.0540 action: 2, epsilon: 1.0000\n",
      "step: 39, Current: 0.0530 action: 2, epsilon: 1.0000\n",
      "step: 49, Current: 0.0520 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.0540 action: 0, epsilon: 1.0000\n",
      "step: 69, Current: 0.0530 action: 1, epsilon: 1.0000\n",
      "step: 79, Current: 0.0520 action: 0, epsilon: 1.0000\n",
      "step: 89, Current: 0.0490 action: 0, epsilon: 1.0000\n",
      "step: 99, Current: 0.0550 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.0540 action: 1, epsilon: 1.0000\n",
      "step: 119, Current: 0.0550 action: 1, epsilon: 1.0000\n",
      "step: 129, Current: 0.0540 action: 0, epsilon: 1.0000\n",
      "step: 139, Current: 0.0540 action: 2, epsilon: 1.0000\n",
      "step: 149, Current: 0.0550 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.0540 action: 1, epsilon: 1.0000\n",
      "step: 169, Current: 0.0560 action: 1, epsilon: 1.0000\n",
      "step: 179, Current: 0.0550 action: 1, epsilon: 1.0000\n",
      "step: 189, Current: 0.0490 action: 0, epsilon: 1.0000\n",
      "step: 199, Current: 0.0480 action: 1, epsilon: 1.0000\n",
      "step: 209, Current: 0.0470 action: 0, epsilon: 1.0000\n",
      "step: 219, Current: 0.0470 action: 2, epsilon: 1.0000\n",
      "step: 229, Current: 0.0470 action: 0, epsilon: 1.0000\n",
      "step: 239, Current: 0.0490 action: 2, epsilon: 1.0000\n",
      "step: 249, Current: 0.0450 action: 1, epsilon: 1.0000\n",
      "step: 259, Current: 0.0470 action: 0, epsilon: 1.0000\n",
      "step: 269, Current: 0.0480 action: 1, epsilon: 1.0000\n",
      "step: 279, Current: 0.0450 action: 0, epsilon: 1.0000\n",
      "step: 289, Current: 0.0450 action: 0, epsilon: 1.0000\n",
      "step: 299, Current: 0.0420 action: 0, epsilon: 1.0000\n",
      "Episode 2(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.2500 action: 1, epsilon: 1.0000\n",
      "step: 19, Current: 0.2480 action: 1, epsilon: 1.0000\n",
      "step: 29, Current: 0.2470 action: 1, epsilon: 1.0000\n",
      "step: 39, Current: 0.2440 action: 0, epsilon: 1.0000\n",
      "step: 49, Current: 0.2440 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.2410 action: 0, epsilon: 1.0000\n",
      "step: 69, Current: 0.2360 action: 0, epsilon: 1.0000\n",
      "step: 79, Current: 0.2370 action: 0, epsilon: 1.0000\n",
      "step: 89, Current: 0.2400 action: 1, epsilon: 1.0000\n",
      "step: 99, Current: 0.2380 action: 1, epsilon: 1.0000\n",
      "step: 109, Current: 0.2340 action: 1, epsilon: 1.0000\n",
      "step: 119, Current: 0.2330 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.2350 action: 2, epsilon: 1.0000\n",
      "step: 139, Current: 0.2340 action: 2, epsilon: 1.0000\n",
      "step: 149, Current: 0.2310 action: 1, epsilon: 1.0000\n",
      "step: 159, Current: 0.2340 action: 1, epsilon: 1.0000\n",
      "step: 169, Current: 0.2390 action: 1, epsilon: 1.0000\n",
      "step: 179, Current: 0.2420 action: 2, epsilon: 1.0000\n",
      "step: 189, Current: 0.2430 action: 0, epsilon: 1.0000\n",
      "step: 199, Current: 0.2460 action: 1, epsilon: 1.0000\n",
      "step: 209, Current: 0.2490 action: 2, epsilon: 1.0000\n",
      "step: 219, Current: 0.2470 action: 1, epsilon: 1.0000\n",
      "step: 229, Current: 0.2470 action: 0, epsilon: 1.0000\n",
      "step: 239, Current: 0.2500 action: 0, epsilon: 1.0000\n",
      "step: 249, Current: 0.2540 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.2530 action: 2, epsilon: 1.0000\n",
      "step: 269, Current: 0.2520 action: 2, epsilon: 1.0000\n",
      "step: 279, Current: 0.2570 action: 2, epsilon: 1.0000\n",
      "step: 289, Current: 0.2590 action: 2, epsilon: 1.0000\n",
      "step: 299, Current: 0.2630 action: 0, epsilon: 1.0000\n",
      "Episode 3(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.0220 action: 1, epsilon: 1.0000\n",
      "step: 19, Current: 0.0270 action: 2, epsilon: 1.0000\n",
      "step: 29, Current: 0.0260 action: 1, epsilon: 1.0000\n",
      "step: 39, Current: 0.0290 action: 1, epsilon: 1.0000\n",
      "step: 49, Current: 0.0280 action: 2, epsilon: 1.0000\n",
      "step: 59, Current: 0.0290 action: 2, epsilon: 1.0000\n",
      "step: 69, Current: 0.0290 action: 2, epsilon: 1.0000\n",
      "step: 79, Current: 0.0270 action: 1, epsilon: 1.0000\n",
      "step: 89, Current: 0.0270 action: 0, epsilon: 1.0000\n",
      "step: 99, Current: 0.0250 action: 0, epsilon: 1.0000\n",
      "step: 109, Current: 0.0270 action: 0, epsilon: 1.0000\n",
      "step: 119, Current: 0.0250 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.0240 action: 2, epsilon: 1.0000\n",
      "step: 139, Current: 0.0260 action: 2, epsilon: 1.0000\n",
      "step: 149, Current: 0.0280 action: 1, epsilon: 1.0000\n",
      "step: 159, Current: 0.0280 action: 0, epsilon: 1.0000\n",
      "step: 169, Current: 0.0270 action: 1, epsilon: 1.0000\n",
      "step: 179, Current: 0.0280 action: 0, epsilon: 1.0000\n",
      "step: 189, Current: 0.0290 action: 0, epsilon: 1.0000\n",
      "step: 199, Current: 0.0260 action: 1, epsilon: 1.0000\n",
      "step: 209, Current: 0.0240 action: 0, epsilon: 1.0000\n",
      "step: 219, Current: 0.0290 action: 2, epsilon: 1.0000\n",
      "step: 229, Current: 0.0310 action: 1, epsilon: 1.0000\n",
      "step: 239, Current: 0.0280 action: 1, epsilon: 1.0000\n",
      "step: 249, Current: 0.0290 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.0310 action: 2, epsilon: 1.0000\n",
      "step: 269, Current: 0.0310 action: 2, epsilon: 1.0000\n",
      "step: 279, Current: 0.0290 action: 0, epsilon: 1.0000\n",
      "step: 289, Current: 0.0340 action: 2, epsilon: 1.0000\n",
      "step: 299, Current: 0.0310 action: 0, epsilon: 1.0000\n",
      "Episode 4(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.0750 action: 2, epsilon: 1.0000\n",
      "step: 19, Current: 0.0760 action: 2, epsilon: 1.0000\n",
      "step: 29, Current: 0.0730 action: 1, epsilon: 1.0000\n",
      "step: 39, Current: 0.0690 action: 0, epsilon: 1.0000\n",
      "step: 49, Current: 0.0670 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.0650 action: 0, epsilon: 1.0000\n",
      "step: 69, Current: 0.0650 action: 0, epsilon: 1.0000\n",
      "step: 79, Current: 0.0650 action: 2, epsilon: 1.0000\n",
      "step: 89, Current: 0.0670 action: 1, epsilon: 1.0000\n",
      "step: 99, Current: 0.0680 action: 0, epsilon: 1.0000\n",
      "step: 109, Current: 0.0650 action: 2, epsilon: 1.0000\n",
      "step: 119, Current: 0.0690 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.0700 action: 0, epsilon: 1.0000\n",
      "step: 139, Current: 0.0730 action: 2, epsilon: 1.0000\n",
      "step: 149, Current: 0.0730 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.0780 action: 2, epsilon: 1.0000\n",
      "step: 169, Current: 0.0770 action: 2, epsilon: 1.0000\n",
      "step: 179, Current: 0.0750 action: 1, epsilon: 1.0000\n",
      "step: 189, Current: 0.0760 action: 1, epsilon: 1.0000\n",
      "step: 199, Current: 0.0740 action: 2, epsilon: 1.0000\n",
      "step: 209, Current: 0.0740 action: 0, epsilon: 1.0000\n",
      "step: 219, Current: 0.0760 action: 2, epsilon: 1.0000\n",
      "step: 229, Current: 0.0740 action: 2, epsilon: 1.0000\n",
      "step: 239, Current: 0.0760 action: 1, epsilon: 1.0000\n",
      "step: 249, Current: 0.0750 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.0720 action: 1, epsilon: 1.0000\n",
      "step: 269, Current: 0.0720 action: 0, epsilon: 1.0000\n",
      "step: 279, Current: 0.0740 action: 1, epsilon: 1.0000\n",
      "step: 289, Current: 0.0690 action: 0, epsilon: 1.0000\n",
      "step: 299, Current: 0.0670 action: 0, epsilon: 1.0000\n",
      "Episode 5(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.1430 action: 0, epsilon: 1.0000\n",
      "step: 19, Current: 0.1410 action: 1, epsilon: 1.0000\n",
      "step: 29, Current: 0.1410 action: 0, epsilon: 1.0000\n",
      "step: 39, Current: 0.1430 action: 2, epsilon: 1.0000\n",
      "step: 49, Current: 0.1430 action: 2, epsilon: 1.0000\n",
      "step: 59, Current: 0.1450 action: 2, epsilon: 1.0000\n",
      "step: 69, Current: 0.1440 action: 0, epsilon: 1.0000\n",
      "step: 79, Current: 0.1430 action: 0, epsilon: 1.0000\n",
      "step: 89, Current: 0.1470 action: 2, epsilon: 1.0000\n",
      "step: 99, Current: 0.1480 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.1430 action: 0, epsilon: 1.0000\n",
      "step: 119, Current: 0.1440 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.1430 action: 1, epsilon: 1.0000\n",
      "step: 139, Current: 0.1430 action: 0, epsilon: 1.0000\n",
      "step: 149, Current: 0.1420 action: 0, epsilon: 1.0000\n",
      "step: 159, Current: 0.1440 action: 2, epsilon: 1.0000\n",
      "step: 169, Current: 0.1420 action: 0, epsilon: 1.0000\n",
      "step: 179, Current: 0.1440 action: 1, epsilon: 1.0000\n",
      "step: 189, Current: 0.1500 action: 2, epsilon: 1.0000\n",
      "step: 199, Current: 0.1470 action: 0, epsilon: 1.0000\n",
      "step: 209, Current: 0.1470 action: 2, epsilon: 1.0000\n",
      "step: 219, Current: 0.1470 action: 0, epsilon: 1.0000\n",
      "step: 229, Current: 0.1480 action: 1, epsilon: 1.0000\n",
      "step: 239, Current: 0.1490 action: 2, epsilon: 1.0000\n",
      "step: 249, Current: 0.1510 action: 1, epsilon: 1.0000\n",
      "step: 259, Current: 0.1490 action: 0, epsilon: 1.0000\n",
      "step: 269, Current: 0.1470 action: 0, epsilon: 1.0000\n",
      "step: 279, Current: 0.1460 action: 0, epsilon: 1.0000\n",
      "step: 289, Current: 0.1450 action: 1, epsilon: 1.0000\n",
      "step: 299, Current: 0.1450 action: 1, epsilon: 1.0000\n",
      "Episode 6(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.1820 action: 0, epsilon: 1.0000\n",
      "step: 19, Current: 0.1860 action: 2, epsilon: 1.0000\n",
      "step: 29, Current: 0.1870 action: 1, epsilon: 1.0000\n",
      "step: 39, Current: 0.1910 action: 2, epsilon: 1.0000\n",
      "step: 49, Current: 0.1870 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.1900 action: 1, epsilon: 1.0000\n",
      "step: 69, Current: 0.1920 action: 1, epsilon: 1.0000\n",
      "step: 79, Current: 0.1900 action: 0, epsilon: 1.0000\n",
      "step: 89, Current: 0.1880 action: 1, epsilon: 1.0000\n",
      "step: 99, Current: 0.1920 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.1910 action: 0, epsilon: 1.0000\n",
      "step: 119, Current: 0.1840 action: 0, epsilon: 1.0000\n",
      "step: 129, Current: 0.1890 action: 1, epsilon: 1.0000\n",
      "step: 139, Current: 0.1910 action: 1, epsilon: 1.0000\n",
      "step: 149, Current: 0.1910 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.1960 action: 2, epsilon: 1.0000\n",
      "step: 169, Current: 0.1940 action: 1, epsilon: 1.0000\n",
      "step: 179, Current: 0.1900 action: 2, epsilon: 1.0000\n",
      "step: 189, Current: 0.1920 action: 0, epsilon: 1.0000\n",
      "step: 199, Current: 0.1930 action: 1, epsilon: 1.0000\n",
      "step: 209, Current: 0.1960 action: 2, epsilon: 1.0000\n",
      "step: 219, Current: 0.1950 action: 2, epsilon: 1.0000\n",
      "step: 229, Current: 0.1990 action: 1, epsilon: 1.0000\n",
      "step: 239, Current: 0.2020 action: 0, epsilon: 1.0000\n",
      "step: 249, Current: 0.2010 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.2000 action: 2, epsilon: 1.0000\n",
      "step: 269, Current: 0.1990 action: 2, epsilon: 1.0000\n",
      "step: 279, Current: 0.2030 action: 2, epsilon: 1.0000\n",
      "step: 289, Current: 0.2050 action: 1, epsilon: 1.0000\n",
      "step: 299, Current: 0.2070 action: 0, epsilon: 1.0000\n",
      "Episode 7(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.1550 action: 2, epsilon: 1.0000\n",
      "step: 19, Current: 0.1530 action: 0, epsilon: 1.0000\n",
      "step: 29, Current: 0.1540 action: 0, epsilon: 1.0000\n",
      "step: 39, Current: 0.1560 action: 2, epsilon: 1.0000\n",
      "step: 49, Current: 0.1560 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.1570 action: 1, epsilon: 1.0000\n",
      "step: 69, Current: 0.1600 action: 0, epsilon: 1.0000\n",
      "step: 79, Current: 0.1540 action: 0, epsilon: 1.0000\n",
      "step: 89, Current: 0.1520 action: 1, epsilon: 1.0000\n",
      "step: 99, Current: 0.1570 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.1560 action: 0, epsilon: 1.0000\n",
      "step: 119, Current: 0.1550 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.1550 action: 0, epsilon: 1.0000\n",
      "step: 139, Current: 0.1540 action: 0, epsilon: 1.0000\n",
      "step: 149, Current: 0.1560 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.1590 action: 0, epsilon: 1.0000\n",
      "step: 169, Current: 0.1620 action: 1, epsilon: 1.0000\n",
      "step: 179, Current: 0.1610 action: 0, epsilon: 1.0000\n",
      "step: 189, Current: 0.1560 action: 0, epsilon: 1.0000\n",
      "step: 199, Current: 0.1540 action: 1, epsilon: 1.0000\n",
      "step: 209, Current: 0.1520 action: 2, epsilon: 1.0000\n",
      "step: 219, Current: 0.1470 action: 0, epsilon: 1.0000\n",
      "step: 229, Current: 0.1460 action: 0, epsilon: 1.0000\n",
      "step: 239, Current: 0.1440 action: 2, epsilon: 1.0000\n",
      "step: 249, Current: 0.1440 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.1400 action: 2, epsilon: 1.0000\n",
      "step: 269, Current: 0.1380 action: 2, epsilon: 1.0000\n",
      "step: 279, Current: 0.1360 action: 0, epsilon: 1.0000\n",
      "step: 289, Current: 0.1400 action: 2, epsilon: 1.0000\n",
      "step: 299, Current: 0.1390 action: 2, epsilon: 1.0000\n",
      "Episode 8(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.0050 action: 1, epsilon: 1.0000\n",
      "step: 19, Current: 0.0080 action: 2, epsilon: 1.0000\n",
      "Episode 9(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.2120 action: 2, epsilon: 1.0000\n",
      "step: 19, Current: 0.2120 action: 0, epsilon: 1.0000\n",
      "step: 29, Current: 0.2120 action: 0, epsilon: 1.0000\n",
      "step: 39, Current: 0.2120 action: 2, epsilon: 1.0000\n",
      "step: 49, Current: 0.2110 action: 0, epsilon: 1.0000\n",
      "step: 59, Current: 0.2170 action: 2, epsilon: 1.0000\n",
      "step: 69, Current: 0.2160 action: 0, epsilon: 1.0000\n",
      "step: 79, Current: 0.2190 action: 1, epsilon: 1.0000\n",
      "step: 89, Current: 0.2200 action: 0, epsilon: 1.0000\n",
      "step: 99, Current: 0.2200 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.2160 action: 2, epsilon: 1.0000\n",
      "step: 119, Current: 0.2160 action: 1, epsilon: 1.0000\n",
      "step: 129, Current: 0.2190 action: 0, epsilon: 1.0000\n",
      "step: 139, Current: 0.2220 action: 1, epsilon: 1.0000\n",
      "step: 149, Current: 0.2220 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.2200 action: 1, epsilon: 1.0000\n",
      "step: 169, Current: 0.2160 action: 2, epsilon: 1.0000\n",
      "step: 179, Current: 0.2180 action: 0, epsilon: 1.0000\n",
      "step: 189, Current: 0.2210 action: 1, epsilon: 1.0000\n",
      "step: 199, Current: 0.2250 action: 2, epsilon: 1.0000\n",
      "step: 209, Current: 0.2220 action: 2, epsilon: 1.0000\n",
      "step: 219, Current: 0.2240 action: 1, epsilon: 1.0000\n",
      "step: 229, Current: 0.2220 action: 1, epsilon: 1.0000\n",
      "step: 239, Current: 0.2240 action: 2, epsilon: 1.0000\n",
      "step: 249, Current: 0.2220 action: 0, epsilon: 1.0000\n",
      "step: 259, Current: 0.2230 action: 1, epsilon: 1.0000\n",
      "step: 269, Current: 0.2260 action: 1, epsilon: 1.0000\n",
      "step: 279, Current: 0.2240 action: 2, epsilon: 1.0000\n",
      "step: 289, Current: 0.2230 action: 2, epsilon: 1.0000\n",
      "step: 299, Current: 0.2250 action: 2, epsilon: 1.0000\n",
      "Episode 10(starting epsilon: 1.0):\n",
      "step: 9, Current: 0.2780 action: 1, epsilon: 1.0000\n",
      "step: 19, Current: 0.2760 action: 1, epsilon: 1.0000\n",
      "step: 29, Current: 0.2720 action: 0, epsilon: 1.0000\n",
      "step: 39, Current: 0.2690 action: 0, epsilon: 1.0000\n",
      "step: 49, Current: 0.2710 action: 1, epsilon: 1.0000\n",
      "step: 59, Current: 0.2650 action: 2, epsilon: 1.0000\n",
      "step: 69, Current: 0.2640 action: 1, epsilon: 1.0000\n",
      "step: 79, Current: 0.2660 action: 2, epsilon: 1.0000\n",
      "step: 89, Current: 0.2660 action: 1, epsilon: 1.0000\n",
      "step: 99, Current: 0.2650 action: 2, epsilon: 1.0000\n",
      "step: 109, Current: 0.2610 action: 0, epsilon: 1.0000\n",
      "step: 119, Current: 0.2600 action: 2, epsilon: 1.0000\n",
      "step: 129, Current: 0.2590 action: 1, epsilon: 1.0000\n",
      "step: 139, Current: 0.2610 action: 0, epsilon: 1.0000\n",
      "step: 149, Current: 0.2620 action: 2, epsilon: 1.0000\n",
      "step: 159, Current: 0.2600 action: 1, epsilon: 1.0000\n",
      "step: 169, Current: 0.2630 action: 2, epsilon: 1.0000\n",
      "step: 179, Current: 0.2600 action: 0, epsilon: 1.0000\n",
      "step: 189, Current: 0.2650 action: 1, epsilon: 1.0000\n",
      "step: 199, Current: 0.2620 action: 0, epsilon: 1.0000\n",
      "step: 209, Current: 0.2630 action: 1, epsilon: 1.0000\n",
      "step: 219, Current: 0.2610 action: 0, epsilon: 1.0000\n",
      "step: 229, Current: 0.2660 action: 2, epsilon: 1.0000\n",
      "step: 239, Current: 0.2650 action: 1, epsilon: 1.0000\n",
      "step: 249, Current: 0.2710 action: 2, epsilon: 1.0000\n",
      "step: 259, Current: 0.2710 action: 0, epsilon: 1.0000\n",
      "step: 269, Current: 0.2730 action: 2, epsilon: 1.0000\n",
      "step: 279, Current: 0.2720 action: 1, epsilon: 1.0000\n",
      "step: 289, Current: 0.2720 action: 2, epsilon: 1.0000\n",
      "step: 299, Current: 0.2680 action: 0, epsilon: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Main loop (or Traning Loop for 10 episodes)\n",
    "\n",
    "num_episodes = 10\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    print(f\"Episode {episode+1}(starting epsilon: {agent.epsilon}):\")\n",
    "    done = False\n",
    "    step = 0 \n",
    "    score = []\n",
    "    state = np.reshape(env.reset(), [1, state_size])\n",
    "\n",
    "    while not done:\n",
    "        step += 1 \n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.append_sample(state, action, reward, next_state, done)\n",
    "        score.append(reward)\n",
    "\n",
    "        if len(agent.memory) >= agent.train_start:\n",
    "            agent.train_model()\n",
    "\n",
    "        if (step+1) % 10 == 0 :\n",
    "            print(f\"step: {step}, Current: {env.current_id:.4f} action: {action}, epsilon: {agent.epsilon:.4f}\")\n",
    "            agent.update_target_model()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            result = np.average(score) \n",
    "            scores.append(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14400000000000002\n",
      "[[0.06013511 0.00921142 0.19199994]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Prediction outputs... (even though it is not correct yet)\n",
    "test_state = np.reshape(env.reset(), [1, state_size])\n",
    "test_q_values = agent.main_model.predict(test_state)\n",
    "action_choice = np.argmax(test_q_values)\n",
    "print(env.current_id)\n",
    "print(test_q_values)\n",
    "print(action_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_states = np.arange(1, 300) * 0.001\n",
    "test_states[0]\n",
    "test_gbp = env._circuit_topology(test_states[0])[-1]\n",
    "test_gbp_target = env.gbp_target\n",
    "test_input = np.array([test_states[0], test_gbp, test_gbp_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00333333, 0.10101015, 0.5       ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_norm = env.normalize_target(test_input)\n",
    "test_input_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have shape (3,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gl/xxgrfgld7zgfc3wy9w6zq6km0000gn/T/ipykernel_94704/1988642984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# np.argmax(test_q_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learning/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_input to have shape (3,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "test_q_values = agent.main_model.predict(test_input_norm)\n",
    "# np.argmax(test_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_id: 0.0010, action_prediction: 1\n",
      "current_id: 0.0020, action_prediction: 1\n",
      "current_id: 0.0030, action_prediction: 1\n",
      "current_id: 0.0040, action_prediction: 1\n",
      "current_id: 0.0050, action_prediction: 1\n",
      "current_id: 0.0060, action_prediction: 1\n",
      "current_id: 0.0070, action_prediction: 1\n",
      "current_id: 0.0080, action_prediction: 1\n",
      "current_id: 0.0090, action_prediction: 1\n",
      "current_id: 0.0100, action_prediction: 2\n",
      "current_id: 0.0110, action_prediction: 2\n",
      "current_id: 0.0120, action_prediction: 2\n",
      "current_id: 0.0130, action_prediction: 2\n",
      "current_id: 0.0140, action_prediction: 2\n",
      "current_id: 0.0150, action_prediction: 2\n",
      "current_id: 0.0160, action_prediction: 2\n",
      "current_id: 0.0170, action_prediction: 2\n",
      "current_id: 0.0180, action_prediction: 2\n",
      "current_id: 0.0190, action_prediction: 2\n",
      "current_id: 0.0200, action_prediction: 2\n",
      "current_id: 0.0210, action_prediction: 2\n",
      "current_id: 0.0220, action_prediction: 2\n",
      "current_id: 0.0230, action_prediction: 2\n",
      "current_id: 0.0240, action_prediction: 2\n",
      "current_id: 0.0250, action_prediction: 2\n",
      "current_id: 0.0260, action_prediction: 2\n",
      "current_id: 0.0270, action_prediction: 2\n",
      "current_id: 0.0280, action_prediction: 2\n",
      "current_id: 0.0290, action_prediction: 2\n",
      "current_id: 0.0300, action_prediction: 2\n",
      "current_id: 0.0310, action_prediction: 2\n",
      "current_id: 0.0320, action_prediction: 2\n",
      "current_id: 0.0330, action_prediction: 2\n",
      "current_id: 0.0340, action_prediction: 2\n",
      "current_id: 0.0350, action_prediction: 2\n",
      "current_id: 0.0360, action_prediction: 2\n",
      "current_id: 0.0370, action_prediction: 2\n",
      "current_id: 0.0380, action_prediction: 2\n",
      "current_id: 0.0390, action_prediction: 2\n",
      "current_id: 0.0400, action_prediction: 2\n",
      "current_id: 0.0410, action_prediction: 2\n",
      "current_id: 0.0420, action_prediction: 2\n",
      "current_id: 0.0430, action_prediction: 2\n",
      "current_id: 0.0440, action_prediction: 2\n",
      "current_id: 0.0450, action_prediction: 2\n",
      "current_id: 0.0460, action_prediction: 2\n",
      "current_id: 0.0470, action_prediction: 2\n",
      "current_id: 0.0480, action_prediction: 2\n",
      "current_id: 0.0490, action_prediction: 2\n",
      "current_id: 0.0500, action_prediction: 2\n",
      "current_id: 0.0510, action_prediction: 2\n",
      "current_id: 0.0520, action_prediction: 2\n",
      "current_id: 0.0530, action_prediction: 2\n",
      "current_id: 0.0540, action_prediction: 2\n",
      "current_id: 0.0550, action_prediction: 2\n",
      "current_id: 0.0560, action_prediction: 2\n",
      "current_id: 0.0570, action_prediction: 2\n",
      "current_id: 0.0580, action_prediction: 2\n",
      "current_id: 0.0590, action_prediction: 2\n",
      "current_id: 0.0600, action_prediction: 2\n",
      "current_id: 0.0610, action_prediction: 2\n",
      "current_id: 0.0620, action_prediction: 2\n",
      "current_id: 0.0630, action_prediction: 2\n",
      "current_id: 0.0640, action_prediction: 2\n",
      "current_id: 0.0650, action_prediction: 2\n",
      "current_id: 0.0660, action_prediction: 2\n",
      "current_id: 0.0670, action_prediction: 2\n",
      "current_id: 0.0680, action_prediction: 2\n",
      "current_id: 0.0690, action_prediction: 2\n",
      "current_id: 0.0700, action_prediction: 2\n",
      "current_id: 0.0710, action_prediction: 2\n",
      "current_id: 0.0720, action_prediction: 2\n",
      "current_id: 0.0730, action_prediction: 2\n",
      "current_id: 0.0740, action_prediction: 2\n",
      "current_id: 0.0750, action_prediction: 2\n",
      "current_id: 0.0760, action_prediction: 2\n",
      "current_id: 0.0770, action_prediction: 2\n",
      "current_id: 0.0780, action_prediction: 2\n",
      "current_id: 0.0790, action_prediction: 2\n",
      "current_id: 0.0800, action_prediction: 2\n",
      "current_id: 0.0810, action_prediction: 2\n",
      "current_id: 0.0820, action_prediction: 2\n",
      "current_id: 0.0830, action_prediction: 2\n",
      "current_id: 0.0840, action_prediction: 2\n",
      "current_id: 0.0850, action_prediction: 2\n",
      "current_id: 0.0860, action_prediction: 2\n",
      "current_id: 0.0870, action_prediction: 2\n",
      "current_id: 0.0880, action_prediction: 2\n",
      "current_id: 0.0890, action_prediction: 2\n",
      "current_id: 0.0900, action_prediction: 2\n",
      "current_id: 0.0910, action_prediction: 2\n",
      "current_id: 0.0920, action_prediction: 2\n",
      "current_id: 0.0930, action_prediction: 2\n",
      "current_id: 0.0940, action_prediction: 2\n",
      "current_id: 0.0950, action_prediction: 2\n",
      "current_id: 0.0960, action_prediction: 2\n",
      "current_id: 0.0970, action_prediction: 2\n",
      "current_id: 0.0980, action_prediction: 2\n",
      "current_id: 0.0990, action_prediction: 2\n",
      "current_id: 0.1000, action_prediction: 2\n",
      "current_id: 0.1010, action_prediction: 2\n",
      "current_id: 0.1020, action_prediction: 2\n",
      "current_id: 0.1030, action_prediction: 2\n",
      "current_id: 0.1040, action_prediction: 2\n",
      "current_id: 0.1050, action_prediction: 2\n",
      "current_id: 0.1060, action_prediction: 2\n",
      "current_id: 0.1070, action_prediction: 2\n",
      "current_id: 0.1080, action_prediction: 2\n",
      "current_id: 0.1090, action_prediction: 2\n",
      "current_id: 0.1100, action_prediction: 2\n",
      "current_id: 0.1110, action_prediction: 2\n",
      "current_id: 0.1120, action_prediction: 2\n",
      "current_id: 0.1130, action_prediction: 2\n",
      "current_id: 0.1140, action_prediction: 2\n",
      "current_id: 0.1150, action_prediction: 2\n",
      "current_id: 0.1160, action_prediction: 2\n",
      "current_id: 0.1170, action_prediction: 2\n",
      "current_id: 0.1180, action_prediction: 2\n",
      "current_id: 0.1190, action_prediction: 2\n",
      "current_id: 0.1200, action_prediction: 2\n",
      "current_id: 0.1210, action_prediction: 2\n",
      "current_id: 0.1220, action_prediction: 2\n",
      "current_id: 0.1230, action_prediction: 2\n",
      "current_id: 0.1240, action_prediction: 2\n",
      "current_id: 0.1250, action_prediction: 2\n",
      "current_id: 0.1260, action_prediction: 2\n",
      "current_id: 0.1270, action_prediction: 2\n",
      "current_id: 0.1280, action_prediction: 2\n",
      "current_id: 0.1290, action_prediction: 2\n",
      "current_id: 0.1300, action_prediction: 2\n",
      "current_id: 0.1310, action_prediction: 2\n",
      "current_id: 0.1320, action_prediction: 2\n",
      "current_id: 0.1330, action_prediction: 2\n",
      "current_id: 0.1340, action_prediction: 2\n",
      "current_id: 0.1350, action_prediction: 2\n",
      "current_id: 0.1360, action_prediction: 2\n",
      "current_id: 0.1370, action_prediction: 2\n",
      "current_id: 0.1380, action_prediction: 2\n",
      "current_id: 0.1390, action_prediction: 2\n",
      "current_id: 0.1400, action_prediction: 2\n",
      "current_id: 0.1410, action_prediction: 2\n",
      "current_id: 0.1420, action_prediction: 2\n",
      "current_id: 0.1430, action_prediction: 2\n",
      "current_id: 0.1440, action_prediction: 2\n",
      "current_id: 0.1450, action_prediction: 2\n",
      "current_id: 0.1460, action_prediction: 2\n",
      "current_id: 0.1470, action_prediction: 2\n",
      "current_id: 0.1480, action_prediction: 2\n",
      "current_id: 0.1490, action_prediction: 2\n",
      "current_id: 0.1500, action_prediction: 2\n",
      "current_id: 0.1510, action_prediction: 2\n",
      "current_id: 0.1520, action_prediction: 2\n",
      "current_id: 0.1530, action_prediction: 2\n",
      "current_id: 0.1540, action_prediction: 2\n",
      "current_id: 0.1550, action_prediction: 2\n",
      "current_id: 0.1560, action_prediction: 2\n",
      "current_id: 0.1570, action_prediction: 2\n",
      "current_id: 0.1580, action_prediction: 2\n",
      "current_id: 0.1590, action_prediction: 2\n",
      "current_id: 0.1600, action_prediction: 2\n",
      "current_id: 0.1610, action_prediction: 2\n",
      "current_id: 0.1620, action_prediction: 2\n",
      "current_id: 0.1630, action_prediction: 2\n",
      "current_id: 0.1640, action_prediction: 2\n",
      "current_id: 0.1650, action_prediction: 2\n",
      "current_id: 0.1660, action_prediction: 2\n",
      "current_id: 0.1670, action_prediction: 2\n",
      "current_id: 0.1680, action_prediction: 2\n",
      "current_id: 0.1690, action_prediction: 2\n",
      "current_id: 0.1700, action_prediction: 2\n",
      "current_id: 0.1710, action_prediction: 2\n",
      "current_id: 0.1720, action_prediction: 2\n",
      "current_id: 0.1730, action_prediction: 2\n",
      "current_id: 0.1740, action_prediction: 2\n",
      "current_id: 0.1750, action_prediction: 2\n",
      "current_id: 0.1760, action_prediction: 2\n",
      "current_id: 0.1770, action_prediction: 2\n",
      "current_id: 0.1780, action_prediction: 2\n",
      "current_id: 0.1790, action_prediction: 2\n",
      "current_id: 0.1800, action_prediction: 2\n",
      "current_id: 0.1810, action_prediction: 2\n",
      "current_id: 0.1820, action_prediction: 2\n",
      "current_id: 0.1830, action_prediction: 2\n",
      "current_id: 0.1840, action_prediction: 2\n",
      "current_id: 0.1850, action_prediction: 2\n",
      "current_id: 0.1860, action_prediction: 2\n",
      "current_id: 0.1870, action_prediction: 2\n",
      "current_id: 0.1880, action_prediction: 2\n",
      "current_id: 0.1890, action_prediction: 2\n",
      "current_id: 0.1900, action_prediction: 2\n",
      "current_id: 0.1910, action_prediction: 2\n",
      "current_id: 0.1920, action_prediction: 2\n",
      "current_id: 0.1930, action_prediction: 2\n",
      "current_id: 0.1940, action_prediction: 2\n",
      "current_id: 0.1950, action_prediction: 2\n",
      "current_id: 0.1960, action_prediction: 2\n",
      "current_id: 0.1970, action_prediction: 2\n",
      "current_id: 0.1980, action_prediction: 2\n",
      "current_id: 0.1990, action_prediction: 2\n",
      "current_id: 0.2000, action_prediction: 2\n",
      "current_id: 0.2010, action_prediction: 2\n",
      "current_id: 0.2020, action_prediction: 2\n",
      "current_id: 0.2030, action_prediction: 2\n",
      "current_id: 0.2040, action_prediction: 2\n",
      "current_id: 0.2050, action_prediction: 2\n",
      "current_id: 0.2060, action_prediction: 2\n",
      "current_id: 0.2070, action_prediction: 2\n",
      "current_id: 0.2080, action_prediction: 2\n",
      "current_id: 0.2090, action_prediction: 2\n",
      "current_id: 0.2100, action_prediction: 2\n",
      "current_id: 0.2110, action_prediction: 2\n",
      "current_id: 0.2120, action_prediction: 2\n",
      "current_id: 0.2130, action_prediction: 2\n",
      "current_id: 0.2140, action_prediction: 2\n",
      "current_id: 0.2150, action_prediction: 2\n",
      "current_id: 0.2160, action_prediction: 2\n",
      "current_id: 0.2170, action_prediction: 2\n",
      "current_id: 0.2180, action_prediction: 2\n",
      "current_id: 0.2190, action_prediction: 2\n",
      "current_id: 0.2200, action_prediction: 2\n",
      "current_id: 0.2210, action_prediction: 2\n",
      "current_id: 0.2220, action_prediction: 2\n",
      "current_id: 0.2230, action_prediction: 2\n",
      "current_id: 0.2240, action_prediction: 2\n",
      "current_id: 0.2250, action_prediction: 2\n",
      "current_id: 0.2260, action_prediction: 2\n",
      "current_id: 0.2270, action_prediction: 2\n",
      "current_id: 0.2280, action_prediction: 2\n",
      "current_id: 0.2290, action_prediction: 2\n",
      "current_id: 0.2300, action_prediction: 2\n",
      "current_id: 0.2310, action_prediction: 2\n",
      "current_id: 0.2320, action_prediction: 2\n",
      "current_id: 0.2330, action_prediction: 2\n",
      "current_id: 0.2340, action_prediction: 2\n",
      "current_id: 0.2350, action_prediction: 2\n",
      "current_id: 0.2360, action_prediction: 2\n",
      "current_id: 0.2370, action_prediction: 2\n",
      "current_id: 0.2380, action_prediction: 2\n",
      "current_id: 0.2390, action_prediction: 2\n",
      "current_id: 0.2400, action_prediction: 2\n",
      "current_id: 0.2410, action_prediction: 2\n",
      "current_id: 0.2420, action_prediction: 2\n",
      "current_id: 0.2430, action_prediction: 2\n",
      "current_id: 0.2440, action_prediction: 2\n",
      "current_id: 0.2450, action_prediction: 2\n",
      "current_id: 0.2460, action_prediction: 2\n",
      "current_id: 0.2470, action_prediction: 2\n",
      "current_id: 0.2480, action_prediction: 2\n",
      "current_id: 0.2490, action_prediction: 2\n",
      "current_id: 0.2500, action_prediction: 2\n",
      "current_id: 0.2510, action_prediction: 2\n",
      "current_id: 0.2520, action_prediction: 2\n",
      "current_id: 0.2530, action_prediction: 2\n",
      "current_id: 0.2540, action_prediction: 2\n",
      "current_id: 0.2550, action_prediction: 2\n",
      "current_id: 0.2560, action_prediction: 2\n",
      "current_id: 0.2570, action_prediction: 2\n",
      "current_id: 0.2580, action_prediction: 2\n",
      "current_id: 0.2590, action_prediction: 2\n",
      "current_id: 0.2600, action_prediction: 2\n",
      "current_id: 0.2610, action_prediction: 2\n",
      "current_id: 0.2620, action_prediction: 2\n",
      "current_id: 0.2630, action_prediction: 2\n",
      "current_id: 0.2640, action_prediction: 2\n",
      "current_id: 0.2650, action_prediction: 2\n",
      "current_id: 0.2660, action_prediction: 2\n",
      "current_id: 0.2670, action_prediction: 2\n",
      "current_id: 0.2680, action_prediction: 2\n",
      "current_id: 0.2690, action_prediction: 2\n",
      "current_id: 0.2700, action_prediction: 2\n",
      "current_id: 0.2710, action_prediction: 2\n",
      "current_id: 0.2720, action_prediction: 2\n",
      "current_id: 0.2730, action_prediction: 2\n",
      "current_id: 0.2740, action_prediction: 2\n",
      "current_id: 0.2750, action_prediction: 2\n",
      "current_id: 0.2760, action_prediction: 2\n",
      "current_id: 0.2770, action_prediction: 2\n",
      "current_id: 0.2780, action_prediction: 2\n",
      "current_id: 0.2790, action_prediction: 2\n",
      "current_id: 0.2800, action_prediction: 2\n",
      "current_id: 0.2810, action_prediction: 2\n",
      "current_id: 0.2820, action_prediction: 2\n",
      "current_id: 0.2830, action_prediction: 2\n",
      "current_id: 0.2840, action_prediction: 2\n",
      "current_id: 0.2850, action_prediction: 2\n",
      "current_id: 0.2860, action_prediction: 2\n",
      "current_id: 0.2870, action_prediction: 2\n",
      "current_id: 0.2880, action_prediction: 2\n",
      "current_id: 0.2890, action_prediction: 2\n",
      "current_id: 0.2900, action_prediction: 2\n",
      "current_id: 0.2910, action_prediction: 2\n",
      "current_id: 0.2920, action_prediction: 2\n",
      "current_id: 0.2930, action_prediction: 2\n",
      "current_id: 0.2940, action_prediction: 2\n",
      "current_id: 0.2950, action_prediction: 2\n",
      "current_id: 0.2960, action_prediction: 2\n",
      "current_id: 0.2970, action_prediction: 2\n",
      "current_id: 0.2980, action_prediction: 2\n",
      "current_id: 0.2990, action_prediction: 2\n"
     ]
    }
   ],
   "source": [
    "test_states = np.arange(1, 300)\n",
    "input_stack = []\n",
    "q_stack = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(test_states)):\n",
    "    test_gbp = env._circuit_topology(test_states[i]*1e-3)[-1]\n",
    "    test_gbp_target = env.gbp_target\n",
    "    test_input = np.array([test_states[i]*1e-3, test_gbp, test_gbp_target])\n",
    "    input_stack.append(test_input)\n",
    "    test_input_norm = np.reshape(env.normalize_target(test_input), [1, state_size])\n",
    "    test_q_values = agent.main_model.predict(test_input_norm)\n",
    "    q_stack.append(test_q_values)\n",
    "    print(f\"current_id: {test_states[i]*1e-3:.4f}, action_prediction: {np.argmax(test_q_values)}\")\n",
    "    predictions.append(np.argmax(test_q_values))\n",
    "\n",
    "input_stack = np.array(input_stack)\n",
    "q_stack = np.array(q_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-03, 6.06060909e+10, 3.00000000e+11],\n",
       "       [2.00000000e-03, 1.11111139e+11, 3.00000000e+11],\n",
       "       [3.00000000e-03, 1.53846179e+11, 3.00000000e+11],\n",
       "       [4.00000000e-03, 1.90476214e+11, 3.00000000e+11],\n",
       "       [5.00000000e-03, 2.22222244e+11, 3.00000000e+11],\n",
       "       [6.00000000e-03, 2.50000021e+11, 3.00000000e+11],\n",
       "       [7.00000000e-03, 2.74509824e+11, 3.00000000e+11],\n",
       "       [8.00000000e-03, 2.96296315e+11, 3.00000000e+11],\n",
       "       [9.00000000e-03, 3.15789491e+11, 3.00000000e+11],\n",
       "       [1.00000000e-02, 3.33333350e+11, 3.00000000e+11],\n",
       "       [1.10000000e-02, 3.49206365e+11, 3.00000000e+11],\n",
       "       [1.20000000e-02, 3.63636379e+11, 3.00000000e+11],\n",
       "       [1.30000000e-02, 3.76811609e+11, 3.00000000e+11],\n",
       "       [1.40000000e-02, 3.88888903e+11, 3.00000000e+11],\n",
       "       [1.50000000e-02, 4.00000013e+11, 3.00000000e+11],\n",
       "       [1.60000000e-02, 4.10256423e+11, 3.00000000e+11],\n",
       "       [1.70000000e-02, 4.19753099e+11, 3.00000000e+11],\n",
       "       [1.80000000e-02, 4.28571440e+11, 3.00000000e+11],\n",
       "       [1.90000000e-02, 4.36781621e+11, 3.00000000e+11],\n",
       "       [2.00000000e-02, 4.44444456e+11, 3.00000000e+11],\n",
       "       [2.10000000e-02, 4.51612914e+11, 3.00000000e+11],\n",
       "       [2.20000000e-02, 4.58333344e+11, 3.00000000e+11],\n",
       "       [2.30000000e-02, 4.64646475e+11, 3.00000000e+11],\n",
       "       [2.40000000e-02, 4.70588245e+11, 3.00000000e+11],\n",
       "       [2.50000000e-02, 4.76190486e+11, 3.00000000e+11],\n",
       "       [2.60000000e-02, 4.81481491e+11, 3.00000000e+11],\n",
       "       [2.70000000e-02, 4.86486495e+11, 3.00000000e+11],\n",
       "       [2.80000000e-02, 4.91228079e+11, 3.00000000e+11],\n",
       "       [2.90000000e-02, 4.95726504e+11, 3.00000000e+11],\n",
       "       [3.00000000e-02, 5.00000008e+11, 3.00000000e+11],\n",
       "       [3.10000000e-02, 5.04065049e+11, 3.00000000e+11],\n",
       "       [3.20000000e-02, 5.07936516e+11, 3.00000000e+11],\n",
       "       [3.30000000e-02, 5.11627915e+11, 3.00000000e+11],\n",
       "       [3.40000000e-02, 5.15151523e+11, 3.00000000e+11],\n",
       "       [3.50000000e-02, 5.18518526e+11, 3.00000000e+11],\n",
       "       [3.60000000e-02, 5.21739138e+11, 3.00000000e+11],\n",
       "       [3.70000000e-02, 5.24822702e+11, 3.00000000e+11],\n",
       "       [3.80000000e-02, 5.27777785e+11, 3.00000000e+11],\n",
       "       [3.90000000e-02, 5.30612252e+11, 3.00000000e+11],\n",
       "       [4.00000000e-02, 5.33333340e+11, 3.00000000e+11],\n",
       "       [4.10000000e-02, 5.35947719e+11, 3.00000000e+11],\n",
       "       [4.20000000e-02, 5.38461545e+11, 3.00000000e+11],\n",
       "       [4.30000000e-02, 5.40880509e+11, 3.00000000e+11],\n",
       "       [4.40000000e-02, 5.43209883e+11, 3.00000000e+11],\n",
       "       [4.50000000e-02, 5.45454552e+11, 3.00000000e+11],\n",
       "       [4.60000000e-02, 5.47619054e+11, 3.00000000e+11],\n",
       "       [4.70000000e-02, 5.49707608e+11, 3.00000000e+11],\n",
       "       [4.80000000e-02, 5.51724144e+11, 3.00000000e+11],\n",
       "       [4.90000000e-02, 5.53672322e+11, 3.00000000e+11],\n",
       "       [5.00000000e-02, 5.55555561e+11, 3.00000000e+11],\n",
       "       [5.10000000e-02, 5.57377055e+11, 3.00000000e+11],\n",
       "       [5.20000000e-02, 5.59139790e+11, 3.00000000e+11],\n",
       "       [5.30000000e-02, 5.60846566e+11, 3.00000000e+11],\n",
       "       [5.40000000e-02, 5.62500005e+11, 3.00000000e+11],\n",
       "       [5.50000000e-02, 5.64102569e+11, 3.00000000e+11],\n",
       "       [5.60000000e-02, 5.65656571e+11, 3.00000000e+11],\n",
       "       [5.70000000e-02, 5.67164184e+11, 3.00000000e+11],\n",
       "       [5.80000000e-02, 5.68627456e+11, 3.00000000e+11],\n",
       "       [5.90000000e-02, 5.70048314e+11, 3.00000000e+11],\n",
       "       [6.00000000e-02, 5.71428576e+11, 3.00000000e+11],\n",
       "       [6.10000000e-02, 5.72769958e+11, 3.00000000e+11],\n",
       "       [6.20000000e-02, 5.74074079e+11, 3.00000000e+11],\n",
       "       [6.30000000e-02, 5.75342470e+11, 3.00000000e+11],\n",
       "       [6.40000000e-02, 5.76576581e+11, 3.00000000e+11],\n",
       "       [6.50000000e-02, 5.77777782e+11, 3.00000000e+11],\n",
       "       [6.60000000e-02, 5.78947373e+11, 3.00000000e+11],\n",
       "       [6.70000000e-02, 5.80086584e+11, 3.00000000e+11],\n",
       "       [6.80000000e-02, 5.81196585e+11, 3.00000000e+11],\n",
       "       [6.90000000e-02, 5.82278485e+11, 3.00000000e+11],\n",
       "       [7.00000000e-02, 5.83333338e+11, 3.00000000e+11],\n",
       "       [7.10000000e-02, 5.84362144e+11, 3.00000000e+11],\n",
       "       [7.20000000e-02, 5.85365858e+11, 3.00000000e+11],\n",
       "       [7.30000000e-02, 5.86345386e+11, 3.00000000e+11],\n",
       "       [7.40000000e-02, 5.87301591e+11, 3.00000000e+11],\n",
       "       [7.50000000e-02, 5.88235298e+11, 3.00000000e+11],\n",
       "       [7.60000000e-02, 5.89147291e+11, 3.00000000e+11],\n",
       "       [7.70000000e-02, 5.90038318e+11, 3.00000000e+11],\n",
       "       [7.80000000e-02, 5.90909095e+11, 3.00000000e+11],\n",
       "       [7.90000000e-02, 5.91760303e+11, 3.00000000e+11],\n",
       "       [8.00000000e-02, 5.92592596e+11, 3.00000000e+11],\n",
       "       [8.10000000e-02, 5.93406597e+11, 3.00000000e+11],\n",
       "       [8.20000000e-02, 5.94202902e+11, 3.00000000e+11],\n",
       "       [8.30000000e-02, 5.94982082e+11, 3.00000000e+11],\n",
       "       [8.40000000e-02, 5.95744684e+11, 3.00000000e+11],\n",
       "       [8.50000000e-02, 5.96491232e+11, 3.00000000e+11],\n",
       "       [8.60000000e-02, 5.97222226e+11, 3.00000000e+11],\n",
       "       [8.70000000e-02, 5.97938148e+11, 3.00000000e+11],\n",
       "       [8.80000000e-02, 5.98639459e+11, 3.00000000e+11],\n",
       "       [8.90000000e-02, 5.99326603e+11, 3.00000000e+11],\n",
       "       [9.00000000e-02, 6.00000003e+11, 3.00000000e+11],\n",
       "       [9.10000000e-02, 6.00660069e+11, 3.00000000e+11],\n",
       "       [9.20000000e-02, 6.01307193e+11, 3.00000000e+11],\n",
       "       [9.30000000e-02, 6.01941751e+11, 3.00000000e+11],\n",
       "       [9.40000000e-02, 6.02564106e+11, 3.00000000e+11],\n",
       "       [9.50000000e-02, 6.03174606e+11, 3.00000000e+11],\n",
       "       [9.60000000e-02, 6.03773588e+11, 3.00000000e+11],\n",
       "       [9.70000000e-02, 6.04361374e+11, 3.00000000e+11],\n",
       "       [9.80000000e-02, 6.04938275e+11, 3.00000000e+11],\n",
       "       [9.90000000e-02, 6.05504590e+11, 3.00000000e+11],\n",
       "       [1.00000000e-01, 6.06060609e+11, 3.00000000e+11],\n",
       "       [1.01000000e-01, 6.06606610e+11, 3.00000000e+11],\n",
       "       [1.02000000e-01, 6.07142860e+11, 3.00000000e+11],\n",
       "       [1.03000000e-01, 6.07669619e+11, 3.00000000e+11],\n",
       "       [1.04000000e-01, 6.08187137e+11, 3.00000000e+11],\n",
       "       [1.05000000e-01, 6.08695655e+11, 3.00000000e+11],\n",
       "       [1.06000000e-01, 6.09195405e+11, 3.00000000e+11],\n",
       "       [1.07000000e-01, 6.09686613e+11, 3.00000000e+11],\n",
       "       [1.08000000e-01, 6.10169494e+11, 3.00000000e+11],\n",
       "       [1.09000000e-01, 6.10644261e+11, 3.00000000e+11],\n",
       "       [1.10000000e-01, 6.11111114e+11, 3.00000000e+11],\n",
       "       [1.11000000e-01, 6.11570251e+11, 3.00000000e+11],\n",
       "       [1.12000000e-01, 6.12021861e+11, 3.00000000e+11],\n",
       "       [1.13000000e-01, 6.12466127e+11, 3.00000000e+11],\n",
       "       [1.14000000e-01, 6.12903228e+11, 3.00000000e+11],\n",
       "       [1.15000000e-01, 6.13333336e+11, 3.00000000e+11],\n",
       "       [1.16000000e-01, 6.13756616e+11, 3.00000000e+11],\n",
       "       [1.17000000e-01, 6.14173231e+11, 3.00000000e+11],\n",
       "       [1.18000000e-01, 6.14583336e+11, 3.00000000e+11],\n",
       "       [1.19000000e-01, 6.14987083e+11, 3.00000000e+11],\n",
       "       [1.20000000e-01, 6.15384618e+11, 3.00000000e+11],\n",
       "       [1.21000000e-01, 6.15776084e+11, 3.00000000e+11],\n",
       "       [1.22000000e-01, 6.16161619e+11, 3.00000000e+11],\n",
       "       [1.23000000e-01, 6.16541356e+11, 3.00000000e+11],\n",
       "       [1.24000000e-01, 6.16915425e+11, 3.00000000e+11],\n",
       "       [1.25000000e-01, 6.17283953e+11, 3.00000000e+11],\n",
       "       [1.26000000e-01, 6.17647061e+11, 3.00000000e+11],\n",
       "       [1.27000000e-01, 6.18004869e+11, 3.00000000e+11],\n",
       "       [1.28000000e-01, 6.18357490e+11, 3.00000000e+11],\n",
       "       [1.29000000e-01, 6.18705038e+11, 3.00000000e+11],\n",
       "       [1.30000000e-01, 6.19047621e+11, 3.00000000e+11],\n",
       "       [1.31000000e-01, 6.19385345e+11, 3.00000000e+11],\n",
       "       [1.32000000e-01, 6.19718312e+11, 3.00000000e+11],\n",
       "       [1.33000000e-01, 6.20046622e+11, 3.00000000e+11],\n",
       "       [1.34000000e-01, 6.20370373e+11, 3.00000000e+11],\n",
       "       [1.35000000e-01, 6.20689657e+11, 3.00000000e+11],\n",
       "       [1.36000000e-01, 6.21004568e+11, 3.00000000e+11],\n",
       "       [1.37000000e-01, 6.21315195e+11, 3.00000000e+11],\n",
       "       [1.38000000e-01, 6.21621624e+11, 3.00000000e+11],\n",
       "       [1.39000000e-01, 6.21923940e+11, 3.00000000e+11],\n",
       "       [1.40000000e-01, 6.22222224e+11, 3.00000000e+11],\n",
       "       [1.41000000e-01, 6.22516558e+11, 3.00000000e+11],\n",
       "       [1.42000000e-01, 6.22807020e+11, 3.00000000e+11],\n",
       "       [1.43000000e-01, 6.23093684e+11, 3.00000000e+11],\n",
       "       [1.44000000e-01, 6.23376626e+11, 3.00000000e+11],\n",
       "       [1.45000000e-01, 6.23655916e+11, 3.00000000e+11],\n",
       "       [1.46000000e-01, 6.23931626e+11, 3.00000000e+11],\n",
       "       [1.47000000e-01, 6.24203824e+11, 3.00000000e+11],\n",
       "       [1.48000000e-01, 6.24472576e+11, 3.00000000e+11],\n",
       "       [1.49000000e-01, 6.24737948e+11, 3.00000000e+11],\n",
       "       [1.50000000e-01, 6.25000002e+11, 3.00000000e+11],\n",
       "       [1.51000000e-01, 6.25258801e+11, 3.00000000e+11],\n",
       "       [1.52000000e-01, 6.25514405e+11, 3.00000000e+11],\n",
       "       [1.53000000e-01, 6.25766873e+11, 3.00000000e+11],\n",
       "       [1.54000000e-01, 6.26016262e+11, 3.00000000e+11],\n",
       "       [1.55000000e-01, 6.26262628e+11, 3.00000000e+11],\n",
       "       [1.56000000e-01, 6.26506026e+11, 3.00000000e+11],\n",
       "       [1.57000000e-01, 6.26746509e+11, 3.00000000e+11],\n",
       "       [1.58000000e-01, 6.26984129e+11, 3.00000000e+11],\n",
       "       [1.59000000e-01, 6.27218937e+11, 3.00000000e+11],\n",
       "       [1.60000000e-01, 6.27450982e+11, 3.00000000e+11],\n",
       "       [1.61000000e-01, 6.27680314e+11, 3.00000000e+11],\n",
       "       [1.62000000e-01, 6.27906979e+11, 3.00000000e+11],\n",
       "       [1.63000000e-01, 6.28131023e+11, 3.00000000e+11],\n",
       "       [1.64000000e-01, 6.28352492e+11, 3.00000000e+11],\n",
       "       [1.65000000e-01, 6.28571430e+11, 3.00000000e+11],\n",
       "       [1.66000000e-01, 6.28787881e+11, 3.00000000e+11],\n",
       "       [1.67000000e-01, 6.29001885e+11, 3.00000000e+11],\n",
       "       [1.68000000e-01, 6.29213485e+11, 3.00000000e+11],\n",
       "       [1.69000000e-01, 6.29422721e+11, 3.00000000e+11],\n",
       "       [1.70000000e-01, 6.29629631e+11, 3.00000000e+11],\n",
       "       [1.71000000e-01, 6.29834256e+11, 3.00000000e+11],\n",
       "       [1.72000000e-01, 6.30036632e+11, 3.00000000e+11],\n",
       "       [1.73000000e-01, 6.30236796e+11, 3.00000000e+11],\n",
       "       [1.74000000e-01, 6.30434784e+11, 3.00000000e+11],\n",
       "       [1.75000000e-01, 6.30630632e+11, 3.00000000e+11],\n",
       "       [1.76000000e-01, 6.30824375e+11, 3.00000000e+11],\n",
       "       [1.77000000e-01, 6.31016045e+11, 3.00000000e+11],\n",
       "       [1.78000000e-01, 6.31205676e+11, 3.00000000e+11],\n",
       "       [1.79000000e-01, 6.31393300e+11, 3.00000000e+11],\n",
       "       [1.80000000e-01, 6.31578949e+11, 3.00000000e+11],\n",
       "       [1.81000000e-01, 6.31762654e+11, 3.00000000e+11],\n",
       "       [1.82000000e-01, 6.31944446e+11, 3.00000000e+11],\n",
       "       [1.83000000e-01, 6.32124354e+11, 3.00000000e+11],\n",
       "       [1.84000000e-01, 6.32302407e+11, 3.00000000e+11],\n",
       "       [1.85000000e-01, 6.32478634e+11, 3.00000000e+11],\n",
       "       [1.86000000e-01, 6.32653063e+11, 3.00000000e+11],\n",
       "       [1.87000000e-01, 6.32825721e+11, 3.00000000e+11],\n",
       "       [1.88000000e-01, 6.32996635e+11, 3.00000000e+11],\n",
       "       [1.89000000e-01, 6.33165831e+11, 3.00000000e+11],\n",
       "       [1.90000000e-01, 6.33333335e+11, 3.00000000e+11],\n",
       "       [1.91000000e-01, 6.33499172e+11, 3.00000000e+11],\n",
       "       [1.92000000e-01, 6.33663368e+11, 3.00000000e+11],\n",
       "       [1.93000000e-01, 6.33825946e+11, 3.00000000e+11],\n",
       "       [1.94000000e-01, 6.33986930e+11, 3.00000000e+11],\n",
       "       [1.95000000e-01, 6.34146343e+11, 3.00000000e+11],\n",
       "       [1.96000000e-01, 6.34304209e+11, 3.00000000e+11],\n",
       "       [1.97000000e-01, 6.34460549e+11, 3.00000000e+11],\n",
       "       [1.98000000e-01, 6.34615386e+11, 3.00000000e+11],\n",
       "       [1.99000000e-01, 6.34768742e+11, 3.00000000e+11],\n",
       "       [2.00000000e-01, 6.34920637e+11, 3.00000000e+11],\n",
       "       [2.01000000e-01, 6.35071092e+11, 3.00000000e+11],\n",
       "       [2.02000000e-01, 6.35220127e+11, 3.00000000e+11],\n",
       "       [2.03000000e-01, 6.35367764e+11, 3.00000000e+11],\n",
       "       [2.04000000e-01, 6.35514020e+11, 3.00000000e+11],\n",
       "       [2.05000000e-01, 6.35658916e+11, 3.00000000e+11],\n",
       "       [2.06000000e-01, 6.35802471e+11, 3.00000000e+11],\n",
       "       [2.07000000e-01, 6.35944702e+11, 3.00000000e+11],\n",
       "       [2.08000000e-01, 6.36085628e+11, 3.00000000e+11],\n",
       "       [2.09000000e-01, 6.36225268e+11, 3.00000000e+11],\n",
       "       [2.10000000e-01, 6.36363638e+11, 3.00000000e+11],\n",
       "       [2.11000000e-01, 6.36500756e+11, 3.00000000e+11],\n",
       "       [2.12000000e-01, 6.36636638e+11, 3.00000000e+11],\n",
       "       [2.13000000e-01, 6.36771302e+11, 3.00000000e+11],\n",
       "       [2.14000000e-01, 6.36904763e+11, 3.00000000e+11],\n",
       "       [2.15000000e-01, 6.37037039e+11, 3.00000000e+11],\n",
       "       [2.16000000e-01, 6.37168143e+11, 3.00000000e+11],\n",
       "       [2.17000000e-01, 6.37298093e+11, 3.00000000e+11],\n",
       "       [2.18000000e-01, 6.37426902e+11, 3.00000000e+11],\n",
       "       [2.19000000e-01, 6.37554587e+11, 3.00000000e+11],\n",
       "       [2.20000000e-01, 6.37681161e+11, 3.00000000e+11],\n",
       "       [2.21000000e-01, 6.37806639e+11, 3.00000000e+11],\n",
       "       [2.22000000e-01, 6.37931036e+11, 3.00000000e+11],\n",
       "       [2.23000000e-01, 6.38054365e+11, 3.00000000e+11],\n",
       "       [2.24000000e-01, 6.38176640e+11, 3.00000000e+11],\n",
       "       [2.25000000e-01, 6.38297874e+11, 3.00000000e+11],\n",
       "       [2.26000000e-01, 6.38418081e+11, 3.00000000e+11],\n",
       "       [2.27000000e-01, 6.38537273e+11, 3.00000000e+11],\n",
       "       [2.28000000e-01, 6.38655464e+11, 3.00000000e+11],\n",
       "       [2.29000000e-01, 6.38772665e+11, 3.00000000e+11],\n",
       "       [2.30000000e-01, 6.38888890e+11, 3.00000000e+11],\n",
       "       [2.31000000e-01, 6.39004151e+11, 3.00000000e+11],\n",
       "       [2.32000000e-01, 6.39118459e+11, 3.00000000e+11],\n",
       "       [2.33000000e-01, 6.39231826e+11, 3.00000000e+11],\n",
       "       [2.34000000e-01, 6.39344264e+11, 3.00000000e+11],\n",
       "       [2.35000000e-01, 6.39455784e+11, 3.00000000e+11],\n",
       "       [2.36000000e-01, 6.39566397e+11, 3.00000000e+11],\n",
       "       [2.37000000e-01, 6.39676115e+11, 3.00000000e+11],\n",
       "       [2.38000000e-01, 6.39784948e+11, 3.00000000e+11],\n",
       "       [2.39000000e-01, 6.39892906e+11, 3.00000000e+11],\n",
       "       [2.40000000e-01, 6.40000001e+11, 3.00000000e+11],\n",
       "       [2.41000000e-01, 6.40106243e+11, 3.00000000e+11],\n",
       "       [2.42000000e-01, 6.40211642e+11, 3.00000000e+11],\n",
       "       [2.43000000e-01, 6.40316207e+11, 3.00000000e+11],\n",
       "       [2.44000000e-01, 6.40419949e+11, 3.00000000e+11],\n",
       "       [2.45000000e-01, 6.40522877e+11, 3.00000000e+11],\n",
       "       [2.46000000e-01, 6.40625001e+11, 3.00000000e+11],\n",
       "       [2.47000000e-01, 6.40726331e+11, 3.00000000e+11],\n",
       "       [2.48000000e-01, 6.40826875e+11, 3.00000000e+11],\n",
       "       [2.49000000e-01, 6.40926642e+11, 3.00000000e+11],\n",
       "       [2.50000000e-01, 6.41025642e+11, 3.00000000e+11],\n",
       "       [2.51000000e-01, 6.41123884e+11, 3.00000000e+11],\n",
       "       [2.52000000e-01, 6.41221375e+11, 3.00000000e+11],\n",
       "       [2.53000000e-01, 6.41318125e+11, 3.00000000e+11],\n",
       "       [2.54000000e-01, 6.41414143e+11, 3.00000000e+11],\n",
       "       [2.55000000e-01, 6.41509435e+11, 3.00000000e+11],\n",
       "       [2.56000000e-01, 6.41604011e+11, 3.00000000e+11],\n",
       "       [2.57000000e-01, 6.41697879e+11, 3.00000000e+11],\n",
       "       [2.58000000e-01, 6.41791046e+11, 3.00000000e+11],\n",
       "       [2.59000000e-01, 6.41883520e+11, 3.00000000e+11],\n",
       "       [2.60000000e-01, 6.41975310e+11, 3.00000000e+11],\n",
       "       [2.61000000e-01, 6.42066422e+11, 3.00000000e+11],\n",
       "       [2.62000000e-01, 6.42156864e+11, 3.00000000e+11],\n",
       "       [2.63000000e-01, 6.42246643e+11, 3.00000000e+11],\n",
       "       [2.64000000e-01, 6.42335768e+11, 3.00000000e+11],\n",
       "       [2.65000000e-01, 6.42424244e+11, 3.00000000e+11],\n",
       "       [2.66000000e-01, 6.42512079e+11, 3.00000000e+11],\n",
       "       [2.67000000e-01, 6.42599279e+11, 3.00000000e+11],\n",
       "       [2.68000000e-01, 6.42685853e+11, 3.00000000e+11],\n",
       "       [2.69000000e-01, 6.42771805e+11, 3.00000000e+11],\n",
       "       [2.70000000e-01, 6.42857144e+11, 3.00000000e+11],\n",
       "       [2.71000000e-01, 6.42941875e+11, 3.00000000e+11],\n",
       "       [2.72000000e-01, 6.43026006e+11, 3.00000000e+11],\n",
       "       [2.73000000e-01, 6.43109542e+11, 3.00000000e+11],\n",
       "       [2.74000000e-01, 6.43192489e+11, 3.00000000e+11],\n",
       "       [2.75000000e-01, 6.43274855e+11, 3.00000000e+11],\n",
       "       [2.76000000e-01, 6.43356645e+11, 3.00000000e+11],\n",
       "       [2.77000000e-01, 6.43437864e+11, 3.00000000e+11],\n",
       "       [2.78000000e-01, 6.43518520e+11, 3.00000000e+11],\n",
       "       [2.79000000e-01, 6.43598617e+11, 3.00000000e+11],\n",
       "       [2.80000000e-01, 6.43678162e+11, 3.00000000e+11],\n",
       "       [2.81000000e-01, 6.43757160e+11, 3.00000000e+11],\n",
       "       [2.82000000e-01, 6.43835618e+11, 3.00000000e+11],\n",
       "       [2.83000000e-01, 6.43913539e+11, 3.00000000e+11],\n",
       "       [2.84000000e-01, 6.43990931e+11, 3.00000000e+11],\n",
       "       [2.85000000e-01, 6.44067798e+11, 3.00000000e+11],\n",
       "       [2.86000000e-01, 6.44144145e+11, 3.00000000e+11],\n",
       "       [2.87000000e-01, 6.44219979e+11, 3.00000000e+11],\n",
       "       [2.88000000e-01, 6.44295303e+11, 3.00000000e+11],\n",
       "       [2.89000000e-01, 6.44370124e+11, 3.00000000e+11],\n",
       "       [2.90000000e-01, 6.44444446e+11, 3.00000000e+11],\n",
       "       [2.91000000e-01, 6.44518274e+11, 3.00000000e+11],\n",
       "       [2.92000000e-01, 6.44591613e+11, 3.00000000e+11],\n",
       "       [2.93000000e-01, 6.44664468e+11, 3.00000000e+11],\n",
       "       [2.94000000e-01, 6.44736843e+11, 3.00000000e+11],\n",
       "       [2.95000000e-01, 6.44808744e+11, 3.00000000e+11],\n",
       "       [2.96000000e-01, 6.44880175e+11, 3.00000000e+11],\n",
       "       [2.97000000e-01, 6.44951141e+11, 3.00000000e+11],\n",
       "       [2.98000000e-01, 6.45021646e+11, 3.00000000e+11],\n",
       "       [2.99000000e-01, 6.45091695e+11, 3.00000000e+11]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for i in range(10):\n",
    "    x.append(i)\n",
    "    if i == 9:\n",
    "        score = np.average(x)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06952335750163284,\n",
       " -0.09249242363974539,\n",
       " -0.05018177708766635,\n",
       " -0.07717268115404423,\n",
       " -0.0879136172619739,\n",
       " -0.09068444853175002,\n",
       " -0.08836906491420263,\n",
       " 0.24581526513086518,\n",
       " -0.09171858707551785,\n",
       " -0.09307572616307076]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ab57b40917d2668bbbeeb6dcb0f927fae8d33b10a6538581e5b2008fa03fdfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
